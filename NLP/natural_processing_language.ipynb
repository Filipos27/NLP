{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Processing Language Amazon reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we are going to make a models to predict are reviews positive or negative. We will use 4 different algorithms for this task. Also we will compare accuracy of balanced dataset and imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing file\n",
    "file = \"./NLP/Books_small_10000.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"reviewerID\": \"A1F2H80A1ZNN1N\", \"asin\": \"B00GDM3NQC\", \"reviewerName\": \"Connie Correll\", \"helpful\": [0, 0], \"reviewText\": \"I bought both boxed sets, books 1-5.  Really a great series!  Start book 1 three weeks ago and just finished book 5.  Sloane Monroe is a great character and being able to follow her through both private life and her PI life gets a reader very involved!  Although clues may be right in front of the reader, there are twists and turns that keep one guessing until the last page!  These are books you won't be disappointed with.\", \"overall\": 5.0, \"summary\": \"Can't stop reading!\", \"unixReviewTime\": 1390435200, \"reviewTime\": \"01 23, 2014\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#opening file\n",
    "with open (file) as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I bought both boxed sets, books 1-5.  Really a great series!  Start book 1 three weeks ago and just finished book 5.  Sloane Monroe is a great character and being able to follow her through both private life and her PI life gets a reader very involved!  Although clues may be right in front of the reader, there are twists and turns that keep one guessing until the last page!  These are books you won't be disappointed with.\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "#printing reviewText and overall\n",
    "with open (file) as f:\n",
    "    for line in f:\n",
    "        review=json.loads(line)\n",
    "        print(review[\"reviewText\"])\n",
    "        print(review[\"overall\"])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I really enjoyed this adventure and look forward to reading more of Robert Spire. I especially liked all the info on global warming. You did a good job on the research.',\n",
       " 4.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making list of reviews and overall\n",
    "reviews=[]\n",
    "with open (file) as f:\n",
    "    for line in f:\n",
    "        review=json.loads(line)\n",
    "        reviews.append((review[\"reviewText\"],review[\"overall\"]))\n",
    "        \n",
    "reviews[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making class for text review,score review and sentiment\n",
    "\n",
    "class Sentiment:\n",
    "    Negative=\"Negative\"\n",
    "    Positive=\"Positive\"\n",
    "    \n",
    "class Review:\n",
    "    def __init__(self,text,score):\n",
    "        self.text=text\n",
    "        self.score=score\n",
    "        self.sentiment=self.get_sentiment()\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score<=3:\n",
    "            return Sentiment.Negative\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            return Sentiment.Positive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review text: I hoped for Mia to have some peace in this book, but her story is so real and raw.  Broken World was so touching and emotional because you go from Mia's trauma to her trying to cope.  I love the way the story displays how there is no \"just bouncing back\" from being sexually assaulted.  Mia showed us how those demons come for you every day and how sometimes they best you. I was so in the moment with Broken World and hurt with Mia because she was surrounded by people but so alone and I understood her feelings.  I found myself wishing I could give her some of my courage and strength or even just to be there for her.  Thank you Lizzy for putting a great character's voice on a strong subject and making it so that other peoples story may be heard through Mia's.\n",
      "Review score: 5.0\n",
      "Review sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "#checking our classes\n",
    "reviews=[]\n",
    "with open (file) as f:\n",
    "    for line in f:\n",
    "        review=json.loads(line)\n",
    "        reviews.append(Review(review[\"reviewText\"],review[\"overall\"]))\n",
    "        \n",
    "        \n",
    "print(\"Review text:\",reviews[5].text)\n",
    "print(\"Review score:\",reviews[5].score)\n",
    "print(\"Review sentiment:\",reviews[5].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many reviews we have\n",
    "len(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing library\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making features and target\n",
    "X=[x.text for x in reviews]\n",
    "y=[x.sentiment for x in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I enjoyed this short book. But it was way way to short ....I can see how easily it would have been to add several chapters.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data on train and test\n",
    "train_X,test_X,train_y,test_y=train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Awakening. Honesty. Action. Separate from each other, and there's not much to go with. Together, however, and there's a moment there, of connection with HaShem, that's supposed to change it all. Or at least Idleman asserts. There are plenty of reviewers that have tackled this very question. Additionally, I'm not reviewing the book, but rather the audiobook. When reviewing an audiobook, the purpose of the review is to ascertain if the audio is one worth listening to. So, on my end, I will assume that you will have decided on the content material, but now you are at a point where you need to decide on traditional reading format or auditory listening format.Heyborne's narration is clear and easy to understand. He reads at a medium pace and pauses slightly in-between sentences to allow readers to keep up. A softer voice, Heyborne's is not one I would mind listening to in the background or while on a drive. Overall, the audiobook edition is a quality edition to consider, breaking out of the mold of subpar quality and providing a voice that can match the author's intent. So, if you're on the fence on reading versus listening, this title is a good title to give audiobooks a go.Disclosure: I was contracted to write an honest review in exchange for a reviewer copy of the product. The opinions stated in this review are solely my own.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Super awesome and super sexy prequel.... I loved every bit of it and cannot wait to start into the series:)\n",
      "  (0, 24685)\t1\n",
      "  (0, 1357)\t2\n",
      "  (0, 24340)\t1\n",
      "  (0, 13002)\t1\n",
      "  (0, 23051)\t1\n",
      "  (0, 17003)\t1\n",
      "  (0, 2926)\t1\n",
      "  (0, 21619)\t1\n",
      "  (0, 23628)\t2\n",
      "  (0, 2205)\t1\n",
      "  (0, 21701)\t1\n",
      "  (0, 18740)\t1\n",
      "  (0, 14656)\t1\n",
      "  (0, 8635)\t1\n",
      "  (0, 3961)\t1\n",
      "  (0, 26265)\t1\n",
      "  (0, 12824)\t1\n"
     ]
    }
   ],
   "source": [
    "#Vectorizing words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer=CountVectorizer()\n",
    "\n",
    "train_X_vector=vectorizer.fit_transform(train_X)\n",
    "test_X_vector=vectorizer.transform(test_X)\n",
    "\n",
    "\n",
    "print(train_X[4])\n",
    "print(train_X_vector[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Linear SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto', kernel='linear')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv=svm.SVC(kernel=\"linear\",gamma=\"auto\")\n",
    "sv.fit(train_X_vector,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_sv=sv.predict(test_X_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8386666666666667"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv.score(test_X_vector,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing classification_report\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.49      0.53      0.51       476\n",
      "    Positive       0.91      0.90      0.90      2524\n",
      "\n",
      "    accuracy                           0.84      3000\n",
      "   macro avg       0.70      0.71      0.71      3000\n",
      "weighted avg       0.84      0.84      0.84      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y,prediction_sv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc=DecisionTreeClassifier()\n",
    "dtc.fit(train_X_vector,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction_dtc=dtc.predict(test_X_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7993333333333333"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.score(test_X_vector,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.34      0.29      0.32       476\n",
      "    Positive       0.87      0.90      0.88      2524\n",
      "\n",
      "    accuracy                           0.80      3000\n",
      "   macro avg       0.61      0.59      0.60      3000\n",
      "weighted avg       0.79      0.80      0.79      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y,prediction_dtc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb=GaussianNB()\n",
    "gnb.fit(train_X_vector.toarray(),train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_gnb=gnb.predict(test_X_vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6453333333333333"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.score(test_X_vector.toarray(),test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.19      0.38      0.25       476\n",
      "    Positive       0.86      0.70      0.77      2524\n",
      "\n",
      "    accuracy                           0.65      3000\n",
      "   macro avg       0.52      0.54      0.51      3000\n",
      "weighted avg       0.75      0.65      0.69      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y,predictions_gnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building LogisticRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression(max_iter=500)\n",
    "lr.fit(train_X_vector,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8703333333333333"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(test_X_vector,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lr=lr.predict(test_X_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.62      0.48      0.54       476\n",
      "    Positive       0.91      0.94      0.92      2524\n",
      "\n",
      "    accuracy                           0.87      3000\n",
      "   macro avg       0.76      0.71      0.73      3000\n",
      "weighted avg       0.86      0.87      0.86      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y,prediction_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import  TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TfidVectorizer for better accuracy\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_X_vectors = vectorizer.fit_transform(train_X)\n",
    "\n",
    "test_X_vectors = vectorizer.transform(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Negative' 'Positive']\n",
      "[1146 5854]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "values, counts = np.unique(train_y, return_counts=True)\n",
    "print(values)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote=SMOTE(sampling_strategy='minority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_smote,train_y_smote=smote.fit_resample(train_X_vectors,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['Negative', 'Positive'], dtype='<U8'), array([5854, 5854]))\n"
     ]
    }
   ],
   "source": [
    "counts = np.unique(train_y_smote, return_counts=True)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto', kernel='linear')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_s=svm.SVC(kernel=\"linear\",gamma=\"auto\")\n",
    "sv_s.fit(train_X_smote,train_y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sv=sv_s.predict(test_X_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.865"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_s.score(test_X_vectors,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.57      0.61      0.59       476\n",
      "    Positive       0.92      0.91      0.92      2524\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.75      0.76      0.75      3000\n",
      "weighted avg       0.87      0.86      0.87      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y,predict_sv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_s=DecisionTreeClassifier()\n",
    "dtc_s.fit(train_X_smote,train_y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dtc=dtc_s.predict(test_X_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7576666666666667"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_s.score(test_X_vectors,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.31      0.43      0.36       476\n",
      "    Positive       0.88      0.82      0.85      2524\n",
      "\n",
      "    accuracy                           0.76      3000\n",
      "   macro avg       0.60      0.62      0.60      3000\n",
      "weighted avg       0.79      0.76      0.77      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y,predict_dtc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_s=GaussianNB()\n",
    "gnb_s.fit(train_X_smote.toarray(),train_y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_gnb=gnb_s.predict(test_X_vectors.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7203333333333334"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_s.score(test_X_vector.toarray(),test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.19      0.37      0.25       476\n",
      "    Positive       0.86      0.70      0.77      2524\n",
      "\n",
      "    accuracy                           0.65      3000\n",
      "   macro avg       0.52      0.54      0.51      3000\n",
      "weighted avg       0.75      0.65      0.69      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y,predict_gnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=500)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_s=LogisticRegression(max_iter=500)\n",
    "lr_s.fit(train_X_smote,train_y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8603333333333333"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_s.score(test_X_vectors,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lr=lr_s.predict(test_X_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.55      0.67      0.60       476\n",
      "    Positive       0.93      0.90      0.92      2524\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.74      0.78      0.76      3000\n",
      "weighted avg       0.87      0.86      0.87      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y,predict_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    Model             | Imbalanced (score)  | Balanced  (score)  |    \n",
    "|----------------------|---------------------|--------------------|\n",
    "|SVM                   |     83.8 %          |      86.5 %        |                   \n",
    "|DecisionTree          |     79.9%           |      75.76 %       |               \n",
    "|Naive Bayes           |     64.53%          |      72.03 %       |  \n",
    "|LogisticRegression    |     87.03%          |      86.03 %       |  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
